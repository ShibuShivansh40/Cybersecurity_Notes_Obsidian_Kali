At first create a AWS Account and create a AWS S3 Bucket and add something into that like a file or something like that.

### Step - 1 : DNS Lookup
Now, here we want a simple DNS Check over the Cloud IP and for that we will be using the command: `nslookup <website.cloud>`

And when we take an IP from the given nslookup results and re-execute the command with that IP Address then, we can get to know the DNS Information about the IP and know what exactly the IP is referring to.
![[Pasted image 20251204122520.png]]


### Step - 2 : S3 Bucket Information
Now, to know about the information of S3 bucket, we will be using the command : `aws s3 ls s3://<website.cloud> --no-sign-request`
![[Pasted image 20251204122802.png]]

### Step - 3 : Downloading the Files from Cloud for Investigation
Now, to download the file, basically we will copy them into our local machine using the command : `aws s3 cp s3://<website.cloud>/filename --no-sign-request saving_name.html`


> Now, create a User at IAM and try to get its Access Keys and save its secret to a file and to login with that user on the CLI, get it done using the commands :  `aws configure --profile <user_name>` & then provide them with the Access Key, Secret Key and other parameters can be None.


### Step - 4 : Access Denied at S3 Bucket
If we try to list the contents of S3 Bucket and we get an access denied error, then we could try to use the profile and then check if there is a permission bug of some sort.

To do that we could use the command : `aws s3 ls --profile <user> s3://<website.local>`
![[Pasted image 20251204150218.png]]
And if we're lucky enough, then we could find some bugs over there.

### Step - 5 : Always look out for Version Control
If you're able to get the contents of the S3 Bucket, then do check if there is a VCS running and we can try to exploit that or not.

![[Pasted image 20251204150601.png]]

> To download the file present inside the bucket we could simply wirte down the command `aws s3 sync --profile <username> s3://url ./directory_at_local`

Now to know all the contents present in each directory we could use a command called `tree`

> To go to a particular Version of Git, we can use the command as : `git checkout <starting_hash>`

> To get all the buckets present in the account, just type in the command : `aws s3 ls --profile <uesrname>`

https://github.com/jordanpotti/AWSBucketDump -> Get this tool for S3 Bucket Enumeration

---
# AWS - Cloud 101 - TryHackMe
